---
title: "FinalExam"
output: pdf_document
---

# Question 1

## a
```{r}
prop_var  <- c(2.90,1.24,0.85,0.72,0.22,0.07)/6
cumsum(prop_var)
```

We would keep the first 3 principal components accounting for 83.2% of the variance of the scaled data

## b

The fourth eigenvalue still represents a meaningful amount of information taking explained variance from .83 to .95. It is significantly above the standard cutoff which for 6 eigenvalues would be 1/6 = .17. This woudl provide a much fuller picture and is likely worth the added complexity.

## c

The first principal component appears to represent overall team strength. where positive pc1 means a more complete team and negative pc1 is a more struggling team. We can look at loading and see that DefPts and DefRush are both negative and the Offenseive poitns offenseive rush yards and offensive pass yards are positive. The only exception is that the Defensive pass coefficient is flipped from ush and points which indicates some nuance on defense.

## d
Principal component 2 contrasts  run heavy offesnses against pass dominant teams with strong pass defense. this is seen with the positive loading on offensive rushing and strong negative loads on defensive points, pass defense, and offensive passing. here a positive score indicates a lot of rushing output but weaker passing offense and defense while a strong neagtive score indicates a pass focused offense with a strong pass defense.

## e
27 has a slightly above average pc1 indicating that both their offense and defense were above average, and a very strong and high pc2 indicating that they were a rush first team 

## f
Point 16 representing the chiefs hovers in the middle of the plot for both PC1 and PC2. They are just above average in PC1 indicating that the oferal team is slightly above average, and they also hover right around 0 for PC2 indicating a balanced team between rushing and passing.

## g

```{r}
load("Data/nfl2024.RData")

vars <- c("DefPts","DevRush","DevPass","OffPts","OffRush","OffPass")

X   <- scale(nfl[ , vars])

pca <- prcomp(X, center = FALSE, scale. = FALSE)
scores <- pca$x

team <- "Arizona Cardinals"
row  <- which(nfl$Team == team) 
z    <- scores[row, 1:4]  

x_std_hat <- as.numeric(z %*% t(pca$rotation[ , 1:4]))

means <- colMeans(nfl[ , vars])
sds   <- apply(nfl[ , vars], 2, sd)

x_hat <- means + x_std_hat * sds
names(x_hat) <- vars

print("Reconstructed Values")
round(x_hat, 2)

actual <- nfl[nfl$Team == team, vars]

#diff <- actual - x_hat
#diff

```

## h
```{r}
library(MASS)

lda_fit <- lda(Playoff ~ ., data = nfl[ , c("Playoff", vars)],
               prior = c(0.5625, 0.4375))

round(lda_fit$scaling, 3)

```
## i
```{r}
scores <- predict(lda_fit)$x
playoff_teams   <- nfl$Team[nfl$Playoff == 1]
playoff_scores  <- scores[nfl$Playoff == 1, 1]

team_low <- playoff_teams[ which.min(playoff_scores) ]
team_low
playoff_scores[ which.min(playoff_scores) ]
```

## j
```{r}
prop.table(table(nfl$Playoff))
```

## k
```{r}
xnew <- data.frame(DefPts = 21.89,
                   DevRush = 124.85,
                   DevPass = 208.82,
                   OffPts = 23.69,
                   OffRush = 132.15,
                   OffPass = 189.54)

predict(lda_fit, newdata = xnew)


```

## l

Im a little confused here so i have recreated the heirarchical clustering appraoch and am using it to produce two groups. 

```{r}
hc_cent <- hclust(dist(scale(nfl[ , vars])), method = "centroid")
groups2 <- cutree(hc_cent, k = 2)

table(Cluster = groups2, Playoff = nfl$Playoff)

```

## m
We must standardize because our metrics are on vary different scales. Points range up to maybe 40 and yards range in the hundreds. without standardizing, the euclidean distance used for clustering would be dominated by the variable with larger variance and would not really represent waht we want it to. By putting our information on the common scale of standard deviations, euclidean distance is now more appropriate and considers all variables equally.

## n

```{r}
hc_ward <- hclust(dist(scale(nfl[ , vars])), method = "ward.D2")
groups2w<- cutree(hc_ward, 2)
table(Cluster = groups2w, Playoff = nfl$Playoff)

mean(groups2w == nfl$Playoff)

```
Hierarchical clustering at level 2 performs quite well only getting three teams incorrect.

## o
It seems group 2 is a strong playoff team as they are teh most positive on pc1. becasue PC2 talks more about play style, it is subjective and we focus on PC1 which leads us to cluster 2. 

## p
```{r}
library(Hotelling)

hot <- hotelling.test(
        x = nfl[nfl$Playoff == 1 , vars],
        y = nfl[nfl$Playoff == 0 , vars])

hot

```

## q
```{r}
pvals <- sapply(vars, \(v)
           t.test(nfl[[v]] ~ nfl$Playoff)$p.value)

alpha <- 0.05 / length(vars)

data.frame(Variable = vars,
           p.value  = round(pvals, 5),
           Significant = pvals <= alpha)

```

## r
LDA and the means test would have been invalidated if we have inequal variance problems. 

# Question 2

## a
PCA and Factor analysis may help identify outliers via dimension reduction making it more easily to visually identify them on a plot

Clustering especially heirarchical will give us an indication of how "difficult" it is for some of these things to cluster together which can also help us identify outliers

Hotelling test is designed for comparing groups so is not useful for identifying individual outliers.

## b
PCA will be great for exploration here, but is likely not used directly for modeling. 

Clustering is the primary useful approach for the traditional customer segmentation. 

If labels are provided which is uncommon for segmentation but common for other similar use cases for this type of analysis, LDA could be used. this would be relevant for target variables like customer churn.

# Question 3
```{r}
mu     <- c(1,2,3)

Sigma  <- matrix(c(3,1,-1, 1,2,0, -1,0,3), 3,3)

A      <- matrix(c(2,-1,0, 0,3,1), nrow = 2, byrow = TRUE)

mu_Y   <- A %*% mu
Sigma_Y<- A %*% Sigma %*% t(A)

mu_Y
Sigma_Y
```

\[
\mathbf Y \;=\;
\begin{pmatrix}
Y_{1}\\[2pt] Y_{2}
\end{pmatrix}
\;\sim\;
\mathcal N_{2}\!\left(
\begin{pmatrix}
0\\[2pt] 9
\end{pmatrix},
\,
\begin{pmatrix}
10 & -2\\[2pt]-2 & 21
\end{pmatrix}
\right).
\]